{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Significant_Energy_Distance(df_1, df_2):\n",
    "    significant_flag = False\n",
    "    threshold = 0.1\n",
    "    feature_detected = []\n",
    "    \n",
    "    feature_names = df_1.columns\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        df_1_feature_values = df_1[feature]\n",
    "        df_2_feature_values = df_2[feature]\n",
    "        \n",
    "        distance = stats.energy_distance(df_1_feature_values, df_2_feature_values)\n",
    "        \n",
    "        if distance > threshold:\n",
    "            print(\"Feature Name: \" + feature + \" Distance: \" + str(distance))\n",
    "            significant_flag = True\n",
    "            feature_detected.append(feature)\n",
    "        \n",
    "    return significant_flag, feature_detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Adult Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 50\n",
    "Batch_Size = 2500\n",
    "Drift_Batch = 9\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "Delay_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Delay = 0\n",
    "    Delay_Stop_Count_Flag = False\n",
    "    \n",
    "#     with open('Datasets/Synthetic_Feature_Adult_Abrupt.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_Feature_Adult_Gradual.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('65', axis=1)\n",
    "                    reference_window_y = reference_window_df['65']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    current_window.extend(batch)\n",
    "                    \n",
    "                    sample_reference_window = random.sample(reference_window, len(current_window))\n",
    "                    \n",
    "#                     print(len(reference_window))\n",
    "#                     print(len(sample_reference_window))\n",
    "                    \n",
    "                    reference_window_df = pd.DataFrame(sample_reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('65', axis=1)\n",
    "                    \n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('65', axis=1)\n",
    "                    current_window_y = current_window_df['65']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if batch_index == Drift_Batch:\n",
    "                        if drift_flag:\n",
    "                            Delay = Batch_Size - 1921\n",
    "                            Delay_Stop_Count_Flag = True\n",
    "                        else:\n",
    "                            Delay = Batch_Size\n",
    "                    elif batch_index > Drift_Batch:\n",
    "                        if not(Delay_Stop_Count_Flag):\n",
    "                            if drift_flag:\n",
    "                                Delay = Delay + Batch_Size - 1921\n",
    "                                Delay_Stop_Count_Flag = True\n",
    "                            else:\n",
    "                                Delay + Batch_Size\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        reference_window.extend(current_window)\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "#                     reference_window = []\n",
    "#                     reference_window.extend(current_window)\n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "        Delay_Total.append(Delay)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "mean_Delay = statistics.mean(Delay_Total)\n",
    "stdev_Delay = statistics.stdev(Delay_Total)\n",
    "\n",
    "print(\"TPR Total: \" + str(TPR_Total))\n",
    "print(\"FPR Total: \" + str(FPR_Total))\n",
    "print(\"Delay Total: \" + str(Delay_Total))\n",
    "print(\"TPR Mean: \" + str(mean_TPR))\n",
    "print(\"TPR Std: \" + str(stdev_TPR))\n",
    "print(\"FPR Mean: \" + str(mean_FPR))\n",
    "print(\"FPR Std: \" + str(stdev_FPR))\n",
    "print(\"Delay Mean: \" + str(mean_Delay))\n",
    "print(\"Delay Std: \" + str(stdev_Delay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bank Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 50\n",
    "Batch_Size = 2500\n",
    "Drift_Batch = 9\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "Delay_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Delay = 0\n",
    "    Delay_Stop_Count_Flag = False\n",
    "    \n",
    "#     with open('Datasets/Synthetic_Feature_Bank_Abrupt.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_Feature_Bank_Gradual.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('48', axis=1)\n",
    "                    reference_window_y = reference_window_df['48']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    current_window.extend(batch)\n",
    "                    \n",
    "                    sample_reference_window = random.sample(reference_window, len(current_window))\n",
    "                    \n",
    "#                     print(len(reference_window))\n",
    "#                     print(len(sample_reference_window))\n",
    "                    \n",
    "                    reference_window_df = pd.DataFrame(sample_reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('48', axis=1)\n",
    "                    \n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('48', axis=1)\n",
    "                    current_window_y = current_window_df['48']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if batch_index == Drift_Batch:\n",
    "                        if drift_flag:\n",
    "                            Delay = Batch_Size - 106\n",
    "                            Delay_Stop_Count_Flag = True\n",
    "                        else:\n",
    "                            Delay = Batch_Size\n",
    "                    elif batch_index > Drift_Batch:\n",
    "                        if not(Delay_Stop_Count_Flag):\n",
    "                            if drift_flag:\n",
    "                                Delay = Delay + Batch_Size - 106\n",
    "                                Delay_Stop_Count_Flag = True\n",
    "                            else:\n",
    "                                Delay + Batch_Size\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        reference_window.extend(current_window)\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "#                     reference_window = []\n",
    "#                     reference_window.extend(current_window)\n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "        Delay_Total.append(Delay)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "mean_Delay = statistics.mean(Delay_Total)\n",
    "stdev_Delay = statistics.stdev(Delay_Total)\n",
    "\n",
    "print(\"TPR Total: \" + str(TPR_Total))\n",
    "print(\"FPR Total: \" + str(FPR_Total))\n",
    "print(\"Delay Total: \" + str(Delay_Total))\n",
    "print(\"TPR Mean: \" + str(mean_TPR))\n",
    "print(\"TPR Std: \" + str(stdev_TPR))\n",
    "print(\"FPR Mean: \" + str(mean_FPR))\n",
    "print(\"FPR Std: \" + str(stdev_FPR))\n",
    "print(\"Delay Mean: \" + str(mean_Delay))\n",
    "print(\"Delay Std: \" + str(stdev_Delay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Credit Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 50\n",
    "Batch_Size = 1500\n",
    "Drift_Batch = 10\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "Delay_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Delay = 0\n",
    "    Delay_Stop_Count_Flag = False\n",
    "    \n",
    "#     with open('Datasets/Synthetic_Feature_Credit_Abrupt.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_Feature_Credit_Gradual.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('26', axis=1)\n",
    "                    reference_window_y = reference_window_df['26']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    current_window.extend(batch)\n",
    "                    \n",
    "                    sample_reference_window = random.sample(reference_window, len(current_window))\n",
    "                    \n",
    "#                     print(len(reference_window))\n",
    "#                     print(len(sample_reference_window))\n",
    "                    \n",
    "                    reference_window_df = pd.DataFrame(sample_reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('26', axis=1)\n",
    "                    \n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('26', axis=1)\n",
    "                    current_window_y = current_window_df['26']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if batch_index == Drift_Batch:\n",
    "                        if drift_flag:\n",
    "                            Delay = Batch_Size - 1\n",
    "                            Delay_Stop_Count_Flag = True\n",
    "                        else:\n",
    "                            Delay = Batch_Size\n",
    "                    elif batch_index > Drift_Batch:\n",
    "                        if not(Delay_Stop_Count_Flag):\n",
    "                            if drift_flag:\n",
    "                                Delay = Delay + Batch_Size - 1\n",
    "                                Delay_Stop_Count_Flag = True\n",
    "                            else:\n",
    "                                Delay + Batch_Size\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        reference_window.extend(current_window)\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "#                     reference_window = []\n",
    "#                     reference_window.extend(current_window)\n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "        Delay_Total.append(Delay)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "mean_Delay = statistics.mean(Delay_Total)\n",
    "stdev_Delay = statistics.stdev(Delay_Total)\n",
    "\n",
    "print(\"TPR Total: \" + str(TPR_Total))\n",
    "print(\"FPR Total: \" + str(FPR_Total))\n",
    "print(\"Delay Total: \" + str(Delay_Total))\n",
    "print(\"TPR Mean: \" + str(mean_TPR))\n",
    "print(\"TPR Std: \" + str(stdev_TPR))\n",
    "print(\"FPR Mean: \" + str(mean_FPR))\n",
    "print(\"FPR Std: \" + str(stdev_FPR))\n",
    "print(\"Delay Mean: \" + str(mean_Delay))\n",
    "print(\"Delay Std: \" + str(stdev_Delay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gamma Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 50\n",
    "Batch_Size = 1000\n",
    "Drift_Batch = 9\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "Delay_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Delay = 0\n",
    "    Delay_Stop_Count_Flag = False\n",
    "    \n",
    "#     with open('Datasets/Synthetic_Feature_Gamma_Abrupt.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_Feature_Gamma_Gradual.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                    reference_window_y = reference_window_df['10']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    current_window.extend(batch)\n",
    "                    \n",
    "                    sample_reference_window = random.sample(reference_window, len(current_window))\n",
    "                    \n",
    "#                     print(len(reference_window))\n",
    "#                     print(len(sample_reference_window))\n",
    "                    \n",
    "                    reference_window_df = pd.DataFrame(sample_reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                    \n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('10', axis=1)\n",
    "                    current_window_y = current_window_df['10']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if batch_index == Drift_Batch:\n",
    "                        if drift_flag:\n",
    "                            Delay = Batch_Size - 510\n",
    "                            Delay_Stop_Count_Flag = True\n",
    "                        else:\n",
    "                            Delay = Batch_Size\n",
    "                    elif batch_index > Drift_Batch:\n",
    "                        if not(Delay_Stop_Count_Flag):\n",
    "                            if drift_flag:\n",
    "                                Delay = Delay + Batch_Size - 510\n",
    "                                Delay_Stop_Count_Flag = True\n",
    "                            else:\n",
    "                                Delay + Batch_Size\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        reference_window.extend(current_window)\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "#                     reference_window = []\n",
    "#                     reference_window.extend(current_window)\n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "        Delay_Total.append(Delay)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "mean_Delay = statistics.mean(Delay_Total)\n",
    "stdev_Delay = statistics.stdev(Delay_Total)\n",
    "\n",
    "print(\"TPR Total: \" + str(TPR_Total))\n",
    "print(\"FPR Total: \" + str(FPR_Total))\n",
    "print(\"Delay Total: \" + str(Delay_Total))\n",
    "print(\"TPR Mean: \" + str(mean_TPR))\n",
    "print(\"TPR Std: \" + str(stdev_TPR))\n",
    "print(\"FPR Mean: \" + str(mean_FPR))\n",
    "print(\"FPR Std: \" + str(stdev_FPR))\n",
    "print(\"Delay Mean: \" + str(mean_Delay))\n",
    "print(\"Delay Std: \" + str(stdev_Delay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SEA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 2\n",
    "Batch_Size = 5000\n",
    "Drift_Batch = 10\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "#     with open('Datasets/Synthetic_MOA_SEA_Abrupt_1.csv') as csv_file:\n",
    "#     with open('Datasets/Synthetic_MOA_SEA_Abrupt_2.csv') as csv_file:\n",
    "#     with open('Datasets/Synthetic_MOA_SEA_Gradual_1.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_MOA_SEA_Gradual_2.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('3', axis=1)\n",
    "                    reference_window_y = reference_window_df['3']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('3', axis=1)\n",
    "                    \n",
    "                    current_window.extend(batch)\n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('3', axis=1)\n",
    "                    current_window_y = current_window_df['3']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "                    \n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "\n",
    "print(TPR_Total)\n",
    "print(FPR_Total)\n",
    "print(mean_TPR)\n",
    "print(stdev_TPR)\n",
    "print(mean_FPR)\n",
    "print(stdev_FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 50\n",
    "Batch_Size = 2500\n",
    "Drift_Batch = 20\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "Delay_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    Delay = 0\n",
    "    Delay_Stop_Count_Flag = False\n",
    "    \n",
    "#     with open('Datasets/Synthetic_MOA_RBF_Abrupt.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_MOA_RBF_Gradual.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                    reference_window_y = reference_window_df['10']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    current_window.extend(batch)\n",
    "                    \n",
    "                    sample_reference_window = random.sample(reference_window, len(current_window))\n",
    "                    \n",
    "#                     print(len(reference_window))\n",
    "#                     print(len(sample_reference_window))\n",
    "                    \n",
    "                    reference_window_df = pd.DataFrame(sample_reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                    \n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('10', axis=1)\n",
    "                    current_window_y = current_window_df['10']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if batch_index == Drift_Batch:\n",
    "                        if drift_flag:\n",
    "                            Delay = Batch_Size - 1\n",
    "                            Delay_Stop_Count_Flag = True\n",
    "                        else:\n",
    "                            Delay = Batch_Size\n",
    "                    elif batch_index > Drift_Batch:\n",
    "                        if not(Delay_Stop_Count_Flag):\n",
    "                            if drift_flag:\n",
    "                                Delay = Delay + Batch_Size - 1\n",
    "                                Delay_Stop_Count_Flag = True\n",
    "                            else:\n",
    "                                Delay + Batch_Size\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        reference_window.extend(current_window)\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "#                     reference_window = []\n",
    "#                     reference_window.extend(current_window)\n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "        Delay_Total.append(Delay)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "mean_Delay = statistics.mean(Delay_Total)\n",
    "stdev_Delay = statistics.stdev(Delay_Total)\n",
    "\n",
    "print(\"TPR Total: \" + str(TPR_Total))\n",
    "print(\"FPR Total: \" + str(FPR_Total))\n",
    "print(\"Delay Total: \" + str(Delay_Total))\n",
    "print(\"TPR Mean: \" + str(mean_TPR))\n",
    "print(\"TPR Std: \" + str(stdev_TPR))\n",
    "print(\"FPR Mean: \" + str(mean_FPR))\n",
    "print(\"FPR Std: \" + str(stdev_FPR))\n",
    "print(\"Delay Mean: \" + str(mean_Delay))\n",
    "print(\"Delay Std: \" + str(stdev_Delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 2500\n",
    "batch_index = 0\n",
    "batch = []\n",
    "batches = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "eval_accuracy_no_change = []\n",
    "eval_accuracy_distance = []\n",
    "    \n",
    "with open('Datasets/Synthetic_MOA_RBF_Abrupt.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        batch.append(row)\n",
    "        if len(batch) == Batch_Size:\n",
    "            batches.append(batch_index)\n",
    "            print(\"Currently Working on Batch \" + str(batch_index))\n",
    "            if batch_index == 0:\n",
    "                reference_window.extend(batch)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                reference_window_y = reference_window_df['10']\n",
    "                \n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y, pred_no_change)\n",
    "                eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                eval_accuracy_distance.append(accuracy_distance)\n",
    "                \n",
    "                    \n",
    "                batch = []\n",
    "                batch_index = batch_index + 1\n",
    "            else:\n",
    "                current_window.extend(batch)\n",
    "                sample_reference_window = random.sample(reference_window, len(current_window))\n",
    "                    \n",
    "                reference_window_df = pd.DataFrame(sample_reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                    \n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('10', axis=1)\n",
    "                current_window_y = current_window_df['10']\n",
    "                    \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                drift_flag, drift_feature = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                if drift_flag:\n",
    "                    print('Drift Detected at Batch ' + str(batch_index))\n",
    "                    drifts_detected.append(batch_index)\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                    random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                    reference_window = []\n",
    "                    reference_window.extend(current_window)\n",
    "        \n",
    "#                     reference_window = []\n",
    "#                     reference_window.extend(current_window)\n",
    "                current_window = []\n",
    "                batch = []\n",
    "                batch_index = batch_index + 1\n",
    "            \n",
    "print(batches)\n",
    "print(eval_accuracy_no_change)\n",
    "print(eval_accuracy_distance)\n",
    "print(drifts_detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Agrawal Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Iteration = 2\n",
    "Batch_Size = 2500\n",
    "Drift_Batch = 20\n",
    "\n",
    "TPR_Total = []\n",
    "FPR_Total = []\n",
    "\n",
    "for i in range(Evaluation_Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    batch_index = 0\n",
    "    batch = []\n",
    "\n",
    "    reference_window = []\n",
    "    current_window = []\n",
    "\n",
    "    drifts_detected = []\n",
    "    eval_accuracy_no_change = []\n",
    "    eval_accuracy_distance = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "#     with open('Datasets/Synthetic_MOA_Agrawal_Abrupt.csv') as csv_file:\n",
    "    with open('Datasets/Synthetic_MOA_Agrawal_Gradual.csv') as csv_file:\n",
    "        drifts_detected = []\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) == Batch_Size:\n",
    "                if batch_index == 0:\n",
    "                    reference_window.extend(batch)\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('9', axis=1)\n",
    "                    reference_window_y = reference_window_df['9']\n",
    "                \n",
    "                    random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "                    random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                    \n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                else:\n",
    "                    reference_window_df = pd.DataFrame(reference_window)\n",
    "                    reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                    reference_window_x = reference_window_df.drop('9', axis=1)\n",
    "                    \n",
    "                    current_window.extend(batch)\n",
    "                    current_window_df = pd.DataFrame(current_window)\n",
    "                    current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                    current_window_x = current_window_df.drop('9', axis=1)\n",
    "                    current_window_y = current_window_df['9']\n",
    "                    \n",
    "                    pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                    accuracy_no_change = accuracy_score(current_window_y, pred_no_change)\n",
    "                    eval_accuracy_no_change.append(accuracy_no_change)\n",
    "                    \n",
    "                    pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                    accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                    eval_accuracy_distance.append(accuracy_distance)\n",
    "                    \n",
    "                    drift_flag, drift_feature = Check_Significant_Energy_Distance(reference_window_x, current_window_x)\n",
    "                    \n",
    "                    if drift_flag:\n",
    "                        print('Drift Detected at Batch ' + str(batch_index))\n",
    "                        drifts_detected.append(batch_index)\n",
    "                        random_forest_distance = RandomForestClassifier(n_estimators=20)\n",
    "                        random_forest_distance.fit(current_window_x, current_window_y)\n",
    "                        reference_window = []\n",
    "                        reference_window.extend(current_window)\n",
    "                        \n",
    "                        if batch_index == Drift_Batch:\n",
    "                            TP = TP + 1\n",
    "                        else:\n",
    "                            FP = FP + 1\n",
    "                    else:\n",
    "                        if batch_index == Drift_Batch:\n",
    "                            FN = FN + 1\n",
    "                        else:\n",
    "                            TN = TN + 1\n",
    "                    \n",
    "                    current_window = []\n",
    "                    batch = []\n",
    "                    batch_index = batch_index + 1\n",
    "                    \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "        TPR_Total.append(TPR)\n",
    "        FPR_Total.append(FPR)\n",
    "\n",
    "mean_TPR = statistics.mean(TPR_Total)\n",
    "stdev_TPR = statistics.stdev(TPR_Total)\n",
    "mean_FPR = statistics.mean(FPR_Total)\n",
    "stdev_FPR = statistics.stdev(FPR_Total)\n",
    "\n",
    "print(TPR_Total)\n",
    "print(FPR_Total)\n",
    "print(mean_TPR)\n",
    "print(stdev_TPR)\n",
    "print(mean_FPR)\n",
    "print(stdev_FPR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
