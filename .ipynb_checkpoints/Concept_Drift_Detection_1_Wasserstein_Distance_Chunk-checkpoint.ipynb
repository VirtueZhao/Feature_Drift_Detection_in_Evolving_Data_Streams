{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math\n",
    "import shap\n",
    "import lime\n",
    "import eli5\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Significant_Wasserstein_Distance(df_1, df_2):\n",
    "    significant_flag = False\n",
    "    threshold = 0.05\n",
    "    \n",
    "    feature_names = df_1.columns\n",
    "    \n",
    "    feature_detected = []\n",
    "    for feature in feature_names:\n",
    "        df_1_feature_values = df_1[feature]\n",
    "        df_2_feature_values = df_2[feature]\n",
    "        \n",
    "        distance = stats.wasserstein_distance(df_1_feature_values, df_2_feature_values)\n",
    "\n",
    "        if distance > threshold:\n",
    "            print(\"Feature Name: \" + feature + \" Distance: \" + str(distance))\n",
    "            significant_flag = True\n",
    "            feature_detected.append(feature)\n",
    "        \n",
    "    return significant_flag, feature_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Significant_Shap(model, reference_x, current_x):\n",
    "    print(\"Checking Significant by Shap values\")\n",
    "    ref_shap_values = shap.TreeExplainer(model).shap_values(reference_x)[1]\n",
    "    cur_shap_values = shap.TreeExplainer(model).shap_values(current_x)[1]\n",
    "    \n",
    "    num_instances = len(ref_shap_values)\n",
    "    num_features = len(ref_shap_values[0])\n",
    "    \n",
    "    ref_feature_shap_values = []\n",
    "    cur_feature_shap_values = []\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        ref_feature_shap_value = []\n",
    "        cur_feature_shap_value = []\n",
    "        for j in range(num_instances):\n",
    "            ref_feature_shap_value.append(ref_shap_values[j][i])\n",
    "            cur_feature_shap_value.append(cur_shap_values[j][i])\n",
    "        ref_feature_shap_values.append(ref_feature_shap_value)\n",
    "        cur_feature_shap_values.append(cur_feature_shap_value)\n",
    "   \n",
    "    update_flag = False\n",
    "    \n",
    "    feature_detected = []\n",
    "    for i in range(num_features):\n",
    "        ref_feature_shap_value = ref_feature_shap_values[i]\n",
    "        cur_feature_shap_value = cur_feature_shap_values[i]\n",
    "        \n",
    "        ref_mean = statistics.mean(ref_feature_shap_value)\n",
    "        ref_stdev = statistics.stdev(ref_feature_shap_value)\n",
    "        ref_size = len(ref_feature_shap_value)\n",
    "        \n",
    "        cur_mean = statistics.mean(cur_feature_shap_value)\n",
    "        cur_stdev = statistics.stdev(cur_feature_shap_value)\n",
    "        cur_size = len(cur_feature_shap_value)\n",
    "        \n",
    "        significant,p = Two_Sample_T_test(ref_mean, cur_mean, ref_stdev, cur_stdev, ref_size, cur_size)\n",
    "        \n",
    "        if significant:\n",
    "            print(\"Shapley Values Drift Detected at Feature \" + str(i))\n",
    "            print(\"P-value: \" + str(p))\n",
    "            update_flag = True\n",
    "            feature_detected.append(i)\n",
    "    return update_flag, feature_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Significant_LIME(model, lime_explainer, reference_window, current_window):\n",
    "    print(\"Checking Significant by LIME values\")\n",
    "    reference_window = reference_window.loc[reference_window['26'].astype(float) == 1.0]\n",
    "    reference_window_x = reference_window.drop('26',axis=1)\n",
    "    ref_lime_distribution = Get_LIME_Distribution(reference_window_x, lime_explainer, model)\n",
    "    \n",
    "    current_window = current_window.loc[current_window['26'].astype(float) == 1.0]\n",
    "    current_window_x = current_window.drop('26',axis=1)\n",
    "    cur_lime_distribution = Get_LIME_Distribution(current_window_x, lime_explainer, model)\n",
    "    \n",
    "    update_flag = False\n",
    "    \n",
    "    feature_detected = []\n",
    "    for i in range(len(ref_lime_distribution)):\n",
    "        ref_lime_mean = ref_lime_distribution[i][0]\n",
    "        ref_lime_stdev = ref_lime_distribution[i][1]\n",
    "        ref_lime_size = ref_lime_distribution[i][2]\n",
    "        \n",
    "        cur_lime_mean = cur_lime_distribution[i][0]\n",
    "        cur_lime_stdev = cur_lime_distribution[i][1]\n",
    "        cur_lime_size = cur_lime_distribution[i][2]\n",
    "        \n",
    "        significant, p = Two_Sample_T_test(ref_lime_mean, cur_lime_mean, ref_lime_stdev, cur_lime_stdev, ref_lime_size,\n",
    "                                          cur_lime_size)\n",
    "        \n",
    "        if significant:\n",
    "            print(\"LIME Values Drift Detected at Feature \" + str(i))\n",
    "            print(\"P-value: \" + str(p))\n",
    "            update_flag = True\n",
    "            feature_detected.append(i)\n",
    "    return update_flag, feature_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_LIME_Distribution(df, explainer, model):\n",
    "    values = df.astype(float).values\n",
    "    feature_names = df.columns\n",
    "    \n",
    "    LIME_values = []\n",
    "    \n",
    "    for value in values:\n",
    "        LIME_value = explainer.explain_instance(value, model.predict_proba, num_features=len(feature_names)).as_list()\n",
    "        LIME_values.append(LIME_value)\n",
    "        \n",
    "    LIME_distributions = []\n",
    "    for i in range(len(feature_names)):\n",
    "        feature_LIME_values = []\n",
    "        for value in LIME_values:\n",
    "            print(value)\n",
    "            feature_LIME_values.append(value[i][1])\n",
    "        feature_LIME_mean = statistics.mean(feature_LIME_values)\n",
    "        feature_LIME_stdev = statistics.stdev(feature_LIME_values)\n",
    "        \n",
    "        LIME_distributions.append((feature_LIME_mean, feature_LIME_stdev, len(feature_LIME_values)))\n",
    "    \n",
    "    return LIME_distributions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Significant_ELI5_Local(model, reference_window, current_window):\n",
    "    print(\"Checking Significant by ELI5 Local Explaination\")\n",
    "    reference_window = reference_window.loc[reference_window['10'].astype(float) == 1.0]\n",
    "    reference_window_x = reference_window.drop('10',axis=1)\n",
    "    ref_eli5_distribution = Get_ELI5_Explaination(model, reference_window_x)\n",
    "    \n",
    "    current_window = current_window.loc[current_window['10'].astype(float) == 1.0]\n",
    "    current_window_x = current_window.drop('10',axis=1)\n",
    "    cur_eli5_distribution = Get_ELI5_Explaination(model, current_window_x)\n",
    "    \n",
    "    feature_detected = []\n",
    "    for feature in ref_eli5_distribution:\n",
    "        if feature in cur_eli5_distribution:\n",
    "            reference_mean = ref_eli5_distribution[feature][0]\n",
    "            current_mean = cur_eli5_distribution[feature][0]\n",
    "            reference_stdev = ref_eli5_distribution[feature][1]\n",
    "            current_stdev = cur_eli5_distribution[feature][1]\n",
    "            reference_size = ref_eli5_distribution[feature][2]\n",
    "            current_size = cur_eli5_distribution[feature][2]\n",
    "                        \n",
    "            eli5_significant, p = Two_Sample_T_test(reference_mean,current_mean,reference_stdev,current_stdev,\n",
    "                                                               reference_size,current_size)\n",
    "                        \n",
    "            if eli5_significant:\n",
    "                print(\"Feature Name: \" + feature)\n",
    "                print(\"P-value: \" + str(p))\n",
    "                feature_detected.append(feature)\n",
    "    return feature_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_ELI5_Explaination(model, df):\n",
    "    values = df.astype(float).values\n",
    "    feature_data = {}\n",
    "    for value in values:\n",
    "        exp = eli5.explain_prediction(model, value)\n",
    "        exp = eli5.format_as_dict(exp)\n",
    "        weights = exp['targets'][0]['feature_weights']['pos']\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            temp = weights[i]\n",
    "            feature = temp['feature']\n",
    "            weight = temp['weight']\n",
    "            if feature not in feature_data:\n",
    "                feature_weights = []\n",
    "                feature_weights.append(weight)\n",
    "                feature_data[feature] = feature_weights\n",
    "            else:\n",
    "                feature_weights = feature_data[feature]\n",
    "                feature_weights.append(weight)\n",
    "                feature_data[feature] = feature_weights\n",
    "    \n",
    "    feature_distribution = {}\n",
    "    for feature in feature_data:\n",
    "        feature_values = feature_data[feature]\n",
    "        feature_mean = statistics.mean(feature_values)\n",
    "        if len(feature_values) > 1:\n",
    "            feature_stdev = statistics.stdev(feature_values)\n",
    "        else:\n",
    "            feature_stdev = 0\n",
    "        feature_distribution[feature] = [feature_mean, feature_stdev, len(feature_values)]\n",
    "    return feature_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Significant_Permutation_Importance(model, reference_window, current_window):\n",
    "    print(\"Checking Significant by Permutation Importance\")\n",
    "    reference_window_x = reference_window.drop('10',axis=1)\n",
    "    reference_window_y = reference_window['10']\n",
    "    ref_pi = eli5.sklearn.PermutationImportance(model,random_state=42).fit(reference_window_x, reference_window_y)\n",
    "    ref_means = ref_pi.feature_importances_\n",
    "    ref_stdevs = ref_pi.feature_importances_std_\n",
    "    ref_size = len(reference_window_y)\n",
    "\n",
    "    current_window_x = current_window.drop('10',axis=1)\n",
    "    current_window_y = current_window['10']\n",
    "    cur_pi = eli5.sklearn.PermutationImportance(model,random_state=42).fit(current_window_x, current_window_y)\n",
    "    cur_means = cur_pi.feature_importances_\n",
    "    cur_stdevs = cur_pi.feature_importances_std_\n",
    "    cur_size = len(current_window_y)\n",
    "    \n",
    "    \n",
    "    feature_detected = []\n",
    "    for i in range(len(ref_means)):\n",
    "        ref_mean = ref_means[i]\n",
    "        ref_stdev = ref_stdevs[i]\n",
    "        cur_mean = cur_means[i]\n",
    "        cur_stdev = cur_stdevs[i]\n",
    "        \n",
    "        pi_significant,p = Two_Sample_T_test(ref_mean, cur_mean, ref_stdev, cur_stdev, ref_size, cur_size)\n",
    "        if pi_significant:\n",
    "            print(\"Feature Name: \" + str(i))\n",
    "            print(\"P-value: \" + str(p))\n",
    "            feature_detected.append(i)\n",
    "    return feature_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Two_Sample_T_test(expected_mean, current_mean, expected_sd, current_sd, expected_size, current_size):\n",
    "    mean_diff = expected_mean - current_mean\n",
    "    size_sum = math.pow(expected_sd, 2) / expected_size + math.pow(current_sd, 2) / current_size\n",
    "    if size_sum == 0:\n",
    "        size_sum = 0.0000000001\n",
    "    t = mean_diff / math.sqrt(size_sum)\n",
    "    df = expected_size + current_size - 2\n",
    "    p = (1 - stats.t.cdf(t, df=df)) * 2\n",
    "\n",
    "    if p < 0.05:\n",
    "        return True, p\n",
    "    else:\n",
    "        return False, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult dataset\n",
    "chunk_size = 2500\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "with open('Datasets/1_adult.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('65', axis=1)\n",
    "                reference_window_y = reference_window_df['65']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('65', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('65', axis=1)\n",
    "                current_window_y = current_window_df['65']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant, distance_feature_detected = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    features = reference_window_x.columns.astype(int)\n",
    "                    \n",
    "#                     shap_significant = Check_Significant_Shap(random_forest_distance, reference_window_x, current_window_x)\n",
    "#                     eli5_feature_detected = Check_Significant_ELI5_Local(random_forest_distance, reference_window_df, current_window_df)\n",
    "                    pi_feature_detected = Check_Significant_Permutation_Importance(random_forest_distance, reference_window_df, current_window_df)\n",
    "                    \n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bank dataset\n",
    "chunk_size = 2500\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "with open('Datasets/2_bank.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('48', axis=1)\n",
    "                reference_window_y = reference_window_df['48']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('48', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('48', axis=1)\n",
    "                current_window_y = current_window_df['48']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant,distance_feature_detected = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    features = reference_window_x.columns.astype(int)\n",
    "#                     shap_significant = Check_Significant_Shap(random_forest_distance, reference_window_x, current_window_x)\n",
    "                    eli5_feature_detected = Check_Significant_ELI5_Local(random_forest_distance, reference_window_df, current_window_df)\n",
    "#                     pi_feature_detected = Check_Significant_Permutation_Importance(random_forest_distance, reference_window_df, current_window_df)\n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Credit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Bank dataset\n",
    "chunk_size = 1500\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "with open('Datasets/3_credit.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('26', axis=1)\n",
    "                reference_window_y = reference_window_df['26']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                lime_explainer = lime.lime_tabular.LimeTabularExplainer(reference_window_x.astype(float).values,\n",
    "                                                                   mode='classification',\n",
    "                                                                   training_labels=reference_window_y,\n",
    "                                                                   feature_names=reference_window_x.columns)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('26', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('26', axis=1)\n",
    "                current_window_y = current_window_df['26']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant, distance_feature_detected = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    features = reference_window_x.columns.astype(int)\n",
    "#                     shap_significant,shap_feature_detected = Check_Significant_Shap(random_forest_distance, reference_window_x, current_window_x)\n",
    "#                     eli5_feature_detected = Check_Significant_ELI5_Local(random_forest_distance, reference_window_df, current_window_df)\n",
    "                    pi_feature_detected = Check_Significant_Permutation_Importance(random_forest_distance, reference_window_df, current_window_df)\n",
    "\n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gamma Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Bank dataset\n",
    "chunk_size = 1000\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "with open('Datasets/4_gamma.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                reference_window_y = reference_window_df['10']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('10', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('10', axis=1)\n",
    "                current_window_y = current_window_df['10']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant,distance_feature_detected = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    features = reference_window_x.columns.astype(int)\n",
    "#                     shap_significant = Check_Significant_Shap(random_forest_distance, reference_window_x, current_window_x)\n",
    "#                     eli5_feature_detected = Check_Significant_ELI5_Local(random_forest_distance, reference_window_df, current_window_df)\n",
    "                    pi_feature_detected = Check_Significant_Permutation_Importance(random_forest_distance, reference_window_df, current_window_df)\n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# elecNorm Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# elecNorm dataset\n",
    "chunk_size = 1440\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "with open('Datasets/5_elecNorm.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('8', axis=1)\n",
    "                reference_window_x = reference_window_x.drop('0', axis=1)\n",
    "                reference_window_y = reference_window_df['8']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('8', axis=1)\n",
    "                reference_window_x = reference_window_x.drop('0', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('8', axis=1)\n",
    "                current_window_x = current_window_x.drop('0', axis=1)\n",
    "                current_window_y = current_window_df['8']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant, distance_feature_detected = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Phishing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# elecNorm dataset\n",
    "chunk_size = 1000\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "with open('Datasets/6_phishing.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('46', axis=1)\n",
    "                reference_window_y = reference_window_df['46']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('46', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('46', axis=1)\n",
    "                current_window_y = current_window_df['46']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant, distance_feature_detected = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunk_num = 0\n",
    "chunk = []\n",
    "\n",
    "reference_window = []\n",
    "current_window = []\n",
    "\n",
    "drifts_detected = []\n",
    "\n",
    "chunks = []\n",
    "no_change_accuracy = []\n",
    "distance_accuracy = []\n",
    "\n",
    "# with open('test_shuffled_4.csv') as csv_file:\n",
    "with open('Datasets/7_SEA.csv') as csv_file:\n",
    "    drifts_detected = []\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        chunk.append(row)\n",
    "        if (len(chunk) == chunk_size):\n",
    "            if (chunk_num == 0):\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                reference_window.extend(chunk)\n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                \n",
    "                reference_window_x = reference_window_df.drop('3', axis=1)\n",
    "                reference_window_y = reference_window_df['3']\n",
    "                \n",
    "                print(\"Train Initial Classifier\")\n",
    "                random_forest_no_change = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_no_change.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                random_forest_distance.fit(reference_window_x, reference_window_y)\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(reference_window_x)\n",
    "                accuracy_no_change = accuracy_score(reference_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(reference_window_x)\n",
    "                accuracy_distance = accuracy_score(reference_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1\n",
    "            else:\n",
    "#                 print(\"Currently working on chunk \" + str(chunk_num))\n",
    "                \n",
    "                reference_window_df = pd.DataFrame(reference_window)\n",
    "                reference_window_df.columns = reference_window_df.columns.astype(str)\n",
    "                reference_window_x = reference_window_df.drop('3', axis=1)\n",
    "                \n",
    "                current_window.extend(chunk)\n",
    "                current_window_df = pd.DataFrame(current_window)\n",
    "                current_window_df.columns = current_window_df.columns.astype(str)\n",
    "                current_window_x = current_window_df.drop('3', axis=1)\n",
    "                current_window_y = current_window_df['3']\n",
    "                \n",
    "                pred_no_change = random_forest_no_change.predict(current_window_x)\n",
    "                accuracy_no_change = accuracy_score(current_window_y,pred_no_change)\n",
    "                no_change_accuracy.append(accuracy_no_change)\n",
    "                print(\"Prediction Accuracy - No Change: \" + str(accuracy_no_change))\n",
    "                \n",
    "                pred_distance = random_forest_distance.predict(current_window_x)\n",
    "                accuracy_distance = accuracy_score(current_window_y, pred_distance)\n",
    "                distance_accuracy.append(accuracy_distance)\n",
    "                print(\"Prediction Accuracy - Distance: \" + str(accuracy_distance))\n",
    "                \n",
    "                chunks.append(chunk_num)\n",
    "                \n",
    "                significant = Check_Significant_Wasserstein_Distance(reference_window_x, current_window_x)\n",
    "                \n",
    "                if significant:\n",
    "                    Check_Significant_Shap(random_forest_distance, reference_window_x, current_window_x)\n",
    "                    drifts_detected.append(chunk_num)\n",
    "                    print('Drift Detected at chunk ' + str(chunk_num))\n",
    "                    print(\"Updating Model\")\n",
    "                    random_forest_distance = RandomForestClassifier(n_estimators=20,random_state=42)\n",
    "                    random_forest_distance.fit(current_window_x,current_window_y)\n",
    "                    \n",
    "                reference_window = []\n",
    "                reference_window.extend(chunk)\n",
    "                current_window = []\n",
    "                \n",
    "                chunk = []\n",
    "                chunk_num = chunk_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(drifts_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(chunks,no_change_accuracy,label='No Change')\n",
    "plt.plot(chunks,distance_accuracy,'-bx',markevery=drifts_detected,label='Distance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks)\n",
    "print(no_change_accuracy)\n",
    "print(distance_accuracy)\n",
    "print(drifts_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks)\n",
    "print(features)\n",
    "print(drifts_detected)\n",
    "print(distance_feature_detected)\n",
    "# print(shap_feature_detected)\n",
    "# print(eli5_feature_detected)\n",
    "# print(pi_feature_detected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
